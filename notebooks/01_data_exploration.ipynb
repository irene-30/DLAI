{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ3pCLzUn6bw"
      },
      "source": [
        "# 1. Data Exploration & Visualization (GSM8K)\n",
        "\n",
        "**Objective:** Load the raw GSM8K dataset, parse it into our `(Prompt, CoT, Solution)` format, and visualize its properties. This will help us understand the data before we build any models."
      ],
      "id": "wQ3pCLzUn6bw"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LFzBtm4n6b9",
        "outputId": "4b0c616b-4397-4fb5-bb64-1761da51054f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets transformers matplotlib seaborn pandas"
      ],
      "id": "5LFzBtm4n6b9"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/irene-30/DLAI.git \"/content/drive/My Drive/DLAI/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AH-oCHzoAmY",
        "outputId": "76eef008-1b58-42d7-8bd4-216138773af8"
      },
      "id": "1AH-oCHzoAmY",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into '/content/drive/My Drive/DLAI'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 125 (delta 30), reused 115 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (125/125), 36.09 KiB | 947.00 KiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWdzwaKln6cC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the 'src' directory to the Python path\n",
        "#sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "%cd /content/DLAI\n",
        "\n",
        "# Now we can import from our source files\n",
        "from src.utils import parse_gsm8k_sample\n",
        "from src.utils import get_llm_tokenizer"
      ],
      "id": "bWdzwaKln6cC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obd-BBQsn6cE"
      },
      "source": [
        "## 1.1 Load Raw Data"
      ],
      "id": "obd-BBQsn6cE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj0aW3d3n6cF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"gsm8k\", \"main\")\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")"
      ],
      "id": "Oj0aW3d3n6cF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3QvFgYln6cI"
      },
      "source": [
        "## 1.2 Inspect a Single Sample"
      ],
      "id": "G3QvFgYln6cI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbBTV00nn6cK"
      },
      "outputs": [],
      "source": [
        "sample = train_data[0]\n",
        "print(\"--- RAW QUESTION ---\")\n",
        "print(sample['question'])\n",
        "\n",
        "print(\"\\n--- RAW ANSWER (CoT + Solution) ---\")\n",
        "print(sample['answer'])"
      ],
      "id": "DbBTV00nn6cK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCLzY3asn6cL"
      },
      "source": [
        "## 1.3 Parse the Sample\n",
        "\n",
        "Let's test our utility function `parse_gsm8k_sample` from `src/utils.py`."
      ],
      "id": "TCLzY3asn6cL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmYy7ATUn6cN"
      },
      "outputs": [],
      "source": [
        "parsed = parse_gsm8k_sample(sample)\n",
        "\n",
        "if parsed:\n",
        "    prompt, cot, solution = parsed\n",
        "    print(\"--- PARSED PROMPT (P) ---\")\n",
        "    print(f\"{prompt!r}\")\n",
        "\n",
        "    print(\"\\n--- PARSED CoT (C) ---\")\n",
        "    print(f\"{cot!r}\")\n",
        "\n",
        "    print(\"\\n--- PARSED SOLUTION (S) ---\")\n",
        "    print(f\"{solution!r}\")\n",
        "else:\n",
        "    print(\"Failed to parse sample.\")"
      ],
      "id": "dmYy7ATUn6cN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nTXqrHjn6cO"
      },
      "source": [
        "## 1.4 Visualize Token Lengths\n",
        "\n",
        "This is the most important visualization. It will show us how long the **Chain-of-Thought (C)** sequences are. If they are long, it justifies our paper's approach of compressing them."
      ],
      "id": "1nTXqrHjn6cO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhEcZepYn6cP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Load our tokenizer to get accurate lengths\n",
        "tokenizer = get_llm_tokenizer()\n",
        "\n",
        "lengths = []\n",
        "for sample in train_data:\n",
        "    parsed = parse_gsm8k_sample(sample)\n",
        "    if parsed:\n",
        "        prompt, cot, solution = parsed\n",
        "        lengths.append({\n",
        "            'prompt_len': len(tokenizer.encode(prompt)),\n",
        "            'cot_len': len(tokenizer.encode(cot)),\n",
        "            'solution_len': len(tokenizer.encode(solution)),\n",
        "            'full_text_len': len(tokenizer.encode(prompt + cot + solution))\n",
        "        })\n",
        "\n",
        "df_lengths = pd.DataFrame(lengths)\n",
        "df_lengths.describe()"
      ],
      "id": "GhEcZepYn6cP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xD_EsiQn6cQ"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "sns.histplot(df_lengths['cot_len'], bins=50, ax=ax1, kde=True)\n",
        "ax1.set_title('Distribution of Chain-of-Thought (CoT) Token Lengths')\n",
        "ax1.set_xlabel('Token Length')\n",
        "\n",
        "sns.histplot(df_lengths['full_text_len'], bins=50, ax=ax2, kde=True)\n",
        "ax2.set_title('Distribution of Full Sample (P+C+S) Token Lengths')\n",
        "ax2.set_xlabel('Token Length')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"--- Analysis ---\")\n",
        "print(f\"Average CoT length: {df_lengths['cot_len'].mean():.2f} tokens\")\n",
        "print(f\"Max CoT length: {df_lengths['cot_len'].max()} tokens\")\n",
        "print(\"Conclusion: The CoT sequences are often long, making them a good target for compression.\")"
      ],
      "id": "2xD_EsiQn6cQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}